{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PropertyID</th>\n",
       "      <th>SaleDollarCnt</th>\n",
       "      <th>TransDate</th>\n",
       "      <th>censusblockgroup</th>\n",
       "      <th>ZoneCodeCounty</th>\n",
       "      <th>Usecode</th>\n",
       "      <th>BedroomCnt</th>\n",
       "      <th>BathroomCnt</th>\n",
       "      <th>FinishedSquareFeet</th>\n",
       "      <th>GarageSquareFeet</th>\n",
       "      <th>LotSizeSquareFeet</th>\n",
       "      <th>StoryCnt</th>\n",
       "      <th>BuiltYear</th>\n",
       "      <th>ViewType</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>BGMedHomeValue</th>\n",
       "      <th>BGMedRent</th>\n",
       "      <th>BGMedYearBuilt</th>\n",
       "      <th>BGPctOwn</th>\n",
       "      <th>BGPctVacant</th>\n",
       "      <th>BGMedIncome</th>\n",
       "      <th>BGPctKids</th>\n",
       "      <th>BGMedAge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>48648941</td>\n",
       "      <td>285000.0</td>\n",
       "      <td>2015-05-23</td>\n",
       "      <td>5.300000e+11</td>\n",
       "      <td>R7</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>7482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47321389</td>\n",
       "      <td>-122213716</td>\n",
       "      <td>107800.0</td>\n",
       "      <td>844.0</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>0.6685</td>\n",
       "      <td>0.0780</td>\n",
       "      <td>42854</td>\n",
       "      <td>0.1924</td>\n",
       "      <td>48.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>48648982</td>\n",
       "      <td>309950.0</td>\n",
       "      <td>2015-08-22</td>\n",
       "      <td>5.300000e+11</td>\n",
       "      <td>R8P</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2170.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>14208</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>47482082</td>\n",
       "      <td>-122244269</td>\n",
       "      <td>181500.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>0.5753</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>54013</td>\n",
       "      <td>0.3718</td>\n",
       "      <td>42.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>48649024</td>\n",
       "      <td>476000.0</td>\n",
       "      <td>2015-08-27</td>\n",
       "      <td>5.300000e+11</td>\n",
       "      <td>SF 7200</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2150.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>6500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47561383</td>\n",
       "      <td>-122308083</td>\n",
       "      <td>344300.0</td>\n",
       "      <td>733.0</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>0.6331</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>56782</td>\n",
       "      <td>0.3207</td>\n",
       "      <td>40.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>48649040</td>\n",
       "      <td>324950.0</td>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>5.300000e+11</td>\n",
       "      <td>R1</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2560.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>47387929</td>\n",
       "      <td>-122279389</td>\n",
       "      <td>284200.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>0.5456</td>\n",
       "      <td>0.0573</td>\n",
       "      <td>44200</td>\n",
       "      <td>0.3359</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>48649057</td>\n",
       "      <td>325000.0</td>\n",
       "      <td>2015-06-20</td>\n",
       "      <td>5.300000e+11</td>\n",
       "      <td>LDR</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1720.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8620</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1948.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>47477068</td>\n",
       "      <td>-122263852</td>\n",
       "      <td>290100.0</td>\n",
       "      <td>802.0</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>0.4267</td>\n",
       "      <td>0.0551</td>\n",
       "      <td>65282</td>\n",
       "      <td>0.1633</td>\n",
       "      <td>44.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11583</td>\n",
       "      <td>124398886</td>\n",
       "      <td>489990.0</td>\n",
       "      <td>2015-09-19</td>\n",
       "      <td>5.300000e+11</td>\n",
       "      <td>MU12</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2550.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2508</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47733216</td>\n",
       "      <td>-121980040</td>\n",
       "      <td>346800.0</td>\n",
       "      <td>1313.0</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>0.7856</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100362</td>\n",
       "      <td>0.4426</td>\n",
       "      <td>34.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11584</td>\n",
       "      <td>124424607</td>\n",
       "      <td>515000.0</td>\n",
       "      <td>2015-09-24</td>\n",
       "      <td>5.300000e+11</td>\n",
       "      <td>R8</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2764.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>4851</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47455220</td>\n",
       "      <td>-122197972</td>\n",
       "      <td>194600.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>0.7270</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>67500</td>\n",
       "      <td>0.4724</td>\n",
       "      <td>38.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11585</td>\n",
       "      <td>124424980</td>\n",
       "      <td>569900.0</td>\n",
       "      <td>2015-09-02</td>\n",
       "      <td>5.300000e+11</td>\n",
       "      <td>R8</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2860.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>4526</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47502826</td>\n",
       "      <td>-122151070</td>\n",
       "      <td>319200.0</td>\n",
       "      <td>696.0</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>0.7703</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>108636</td>\n",
       "      <td>0.3475</td>\n",
       "      <td>34.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11586</td>\n",
       "      <td>124435328</td>\n",
       "      <td>880000.0</td>\n",
       "      <td>2015-09-30</td>\n",
       "      <td>5.300000e+11</td>\n",
       "      <td>SF 7200</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2850.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>7200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47707734</td>\n",
       "      <td>-122312365</td>\n",
       "      <td>402100.0</td>\n",
       "      <td>908.0</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>0.6156</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>84375</td>\n",
       "      <td>0.2121</td>\n",
       "      <td>38.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11587</td>\n",
       "      <td>124435440</td>\n",
       "      <td>572900.0</td>\n",
       "      <td>2015-09-24</td>\n",
       "      <td>5.300000e+11</td>\n",
       "      <td>R8</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2790.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>4526</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47502827</td>\n",
       "      <td>-122151007</td>\n",
       "      <td>319200.0</td>\n",
       "      <td>696.0</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>0.7703</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>108636</td>\n",
       "      <td>0.3475</td>\n",
       "      <td>34.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11588 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PropertyID  SaleDollarCnt  TransDate  censusblockgroup ZoneCodeCounty  \\\n",
       "0        48648941       285000.0 2015-05-23      5.300000e+11             R7   \n",
       "1        48648982       309950.0 2015-08-22      5.300000e+11            R8P   \n",
       "2        48649024       476000.0 2015-08-27      5.300000e+11        SF 7200   \n",
       "3        48649040       324950.0 2015-07-01      5.300000e+11             R1   \n",
       "4        48649057       325000.0 2015-06-20      5.300000e+11            LDR   \n",
       "...           ...            ...        ...               ...            ...   \n",
       "11583   124398886       489990.0 2015-09-19      5.300000e+11           MU12   \n",
       "11584   124424607       515000.0 2015-09-24      5.300000e+11             R8   \n",
       "11585   124424980       569900.0 2015-09-02      5.300000e+11             R8   \n",
       "11586   124435328       880000.0 2015-09-30      5.300000e+11        SF 7200   \n",
       "11587   124435440       572900.0 2015-09-24      5.300000e+11             R8   \n",
       "\n",
       "       Usecode  BedroomCnt  BathroomCnt  FinishedSquareFeet  GarageSquareFeet  \\\n",
       "0            9         4.0         2.00              1900.0             480.0   \n",
       "1            9         3.0         2.00              2170.0             320.0   \n",
       "2            9         4.0         1.00              2150.0             590.0   \n",
       "3            9         4.0         2.25              2560.0               NaN   \n",
       "4            9         4.0         1.75              1720.0               NaN   \n",
       "...        ...         ...          ...                 ...               ...   \n",
       "11583        9         3.0         2.00              2550.0             300.0   \n",
       "11584        9         4.0         2.25              2764.0             620.0   \n",
       "11585        9         3.0         2.75              2860.0             630.0   \n",
       "11586        9         4.0         2.75              2850.0             520.0   \n",
       "11587        9         3.0         2.75              2790.0             660.0   \n",
       "\n",
       "       LotSizeSquareFeet  StoryCnt  BuiltYear  ViewType  Latitude  Longitude  \\\n",
       "0                   7482       1.0     1965.0       NaN  47321389 -122213716   \n",
       "1                  14208       1.0     1953.0      79.0  47482082 -122244269   \n",
       "2                   6500       1.0     1955.0       NaN  47561383 -122308083   \n",
       "3                  15767       1.0     1962.0      79.0  47387929 -122279389   \n",
       "4                   8620       2.0     1948.0      78.0  47477068 -122263852   \n",
       "...                  ...       ...        ...       ...       ...        ...   \n",
       "11583               2508       2.0     2015.0       NaN  47733216 -121980040   \n",
       "11584               4851       2.0     2015.0       NaN  47455220 -122197972   \n",
       "11585               4526       2.0     2015.0       NaN  47502826 -122151070   \n",
       "11586               7200       2.0     2015.0       NaN  47707734 -122312365   \n",
       "11587               4526       2.0     2015.0       NaN  47502827 -122151007   \n",
       "\n",
       "       BGMedHomeValue  BGMedRent  BGMedYearBuilt  BGPctOwn  BGPctVacant  \\\n",
       "0            107800.0      844.0          1975.0    0.6685       0.0780   \n",
       "1            181500.0      925.0          1969.0    0.5753       0.0192   \n",
       "2            344300.0      733.0          1946.0    0.6331       0.0000   \n",
       "3            284200.0      900.0          1977.0    0.5456       0.0573   \n",
       "4            290100.0      802.0          1972.0    0.4267       0.0551   \n",
       "...               ...        ...             ...       ...          ...   \n",
       "11583        346800.0     1313.0          1989.0    0.7856       0.0000   \n",
       "11584        194600.0     1069.0          1961.0    0.7270       0.0000   \n",
       "11585        319200.0      696.0          1972.0    0.7703       0.0000   \n",
       "11586        402100.0      908.0          1953.0    0.6156       0.0000   \n",
       "11587        319200.0      696.0          1972.0    0.7703       0.0000   \n",
       "\n",
       "       BGMedIncome  BGPctKids  BGMedAge  \n",
       "0            42854     0.1924      48.6  \n",
       "1            54013     0.3718      42.6  \n",
       "2            56782     0.3207      40.7  \n",
       "3            44200     0.3359      40.0  \n",
       "4            65282     0.1633      44.4  \n",
       "...            ...        ...       ...  \n",
       "11583       100362     0.4426      34.1  \n",
       "11584        67500     0.4724      38.1  \n",
       "11585       108636     0.3475      34.4  \n",
       "11586        84375     0.2121      38.6  \n",
       "11587       108636     0.3475      34.4  \n",
       "\n",
       "[11588 rows x 24 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NOTES\n",
    "#consider an ensemble of (catboost1 +catboost2 +catboost3 +XGBoost1 + XGBoost2)\n",
    "#handle outliers\n",
    "#feature importance and shaply\n",
    "#custom scorer\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#change working directory\n",
    "#os.chdir(\"C:/Users/wagne/OneDrive - Washington State University (email.wsu.edu)/Application Materials/Grad to Professional/Applications/Zillow\")\n",
    "\n",
    "#set pandas defaults for number of rows and columns to display\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "\n",
    "#read in data\n",
    "dfTrain = pd.read_csv(\"Data Science ZExercise_TRAINING_CONFIDENTIAL1.csv\", parse_dates=['TransDate'])\n",
    "dfTest = pd.read_csv(\"Data Science ZExercise_TEST_CONFIDENTIAL2.csv\", parse_dates=['TransDate'])\n",
    "\n",
    "dfTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks like censusblockgroup was rounded in the csv file, censusblockgroup = 5.300000e+11 for each obs\n",
    "#recover FIPS using FCC Geocode API\n",
    "# the API takes about 40 mins per dataset, to save time I simply import and merge the saved FIPS info\n",
    "\n",
    "dfLatLngTrain = pd.read_csv(\"latlongZillowTrain.csv\")\n",
    "dfTrain = dfTrain.merge(dfLatLngTrain, on='PropertyID')\n",
    "\n",
    "dfLatLngTest = pd.read_csv(\"latlongZillowTest.csv\")\n",
    "dfTest = dfTest.merge(dfLatLngTest, on='PropertyID')\n",
    "\n",
    "# # requests from API  (inspired by https://github.com/jdeferio/FCC-Geocode)\n",
    "\n",
    "# import requests\n",
    "\n",
    "# # Read the data to a Pandas DataFrame\n",
    "# data = pd.read_csv(\"Data Science ZExercise_TEST_CONFIDENTIAL2.csv\")\n",
    "\n",
    "# # Form a list of Lat/Long for geocoding:\n",
    "# latitudes = (data[\"Latitude\"]/1000000).tolist()\n",
    "# longitudes = (data[\"Longitude\"]/1000000).tolist()\n",
    "# zid = data['PropertyID'].tolist()\n",
    "\n",
    "# #get function\n",
    "# def get_fcc_results(latitude,longitude,i):\n",
    "#     \"\"\"\n",
    "#     Get geocode results from FCC API.\n",
    "#     Note, that in the case of multiple FCC geocode results, this function returns details of the FIRST result.\n",
    "#     @param return_full_response: Boolean to indicate if you'd like to return the full response from google. This\n",
    "#                     is useful if you'd like additional location details for storage or parsing later.\n",
    "#     \"\"\"\n",
    "#     # Set up your Geocoding url\n",
    "#     geocode_url = \"https://geo.fcc.gov/api/census/area?lat={}&lon={}&format=json\".format(latitude,longitude)\n",
    "\n",
    "\n",
    "#    # Ping FCC for the reuslts:\n",
    "#     results = requests.get(geocode_url)\n",
    "#     # Results will be in JSON format - convert to dict using requests functionality\n",
    "#     results = results.json()\n",
    "\n",
    "#     # if there's no results or an error, return empty results.\n",
    "#     if len(results['results']) == 0:\n",
    "#         output = {\n",
    "#             \"FIPS\" : None\n",
    "#         }\n",
    "#     else:\n",
    "#         output = {\n",
    "#             \"FIPS\": results['results'][0]['block_fips']\n",
    "#         }\n",
    "\n",
    "#     # Append some other details:\n",
    "#     output['latitudes'] = latitude\n",
    "#     output['longitudes'] = longitude\n",
    "\n",
    "#     # output['number_of_results'] = len(results['results'])\n",
    "#     output['PropertyID'] = zid[i]\n",
    "\n",
    "#     return output\n",
    "\n",
    "# # Create a list to hold results\n",
    "# results = []\n",
    "# i=0\n",
    "# # Go through each lat-long in turn\n",
    "# for latitude, longitude in zip(latitudes, longitudes):\n",
    "#     geocode_result = get_fcc_results(latitude,longitude, i)\n",
    "#     results.append(geocode_result)\n",
    "#     i+=1\n",
    "\n",
    "# pd.DataFrame(results).to_csv('latlongZillowTest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up the data and add some new features\n",
    "\n",
    "def dataPrep(df):\n",
    "    #create a FIPS tract code by dropping ones digit from FIPS block code\n",
    "    tractFIPS = []\n",
    "    FIPS = np.array(df['FIPS']).astype(str)\n",
    "    for i in range(len(FIPS)):\n",
    "        tractFIPS.append(FIPS[i][0:len(FIPS[i])-1])\n",
    "    df['tractFIPS'] = np.array(tractFIPS).astype(str)\n",
    "    df['FIPS'] = np.array(df['FIPS']).astype(str)\n",
    "\n",
    "    #change dates into vars\n",
    "    df['TransDayOfYear'] = df['TransDate'].dt.dayofyear\n",
    "    df['TransDayOfMonth'] = df['TransDate'].dt.day\n",
    "    df['TransDayOfWeek'] = df['TransDate'].dt.dayofweek\n",
    "    df['TransMonth'] = df['TransDate'].dt.month\n",
    "    df['TransQuarter'] = df['TransDate'].dt.quarter\n",
    "    df['TransWeek'] = df['TransDate'].dt.week\n",
    "    \n",
    "    #some time trend vars\n",
    "    df['day'] = df['TransDayOfYear']\n",
    "    df['daysq'] = np.power(df['TransDayOfYear'],2)\n",
    "    df['daycu'] = np.power(df['TransDayOfYear'],3)\n",
    "    df['week'] = df['TransWeek']\n",
    "    df['weeksq'] = np.power(df['TransWeek'],2)\n",
    "    df['weekcu'] = np.power(df['TransWeek'],3)\n",
    "    \n",
    "    #constant for linear regression\n",
    "    df['const'] = 1\n",
    "\n",
    "    #use intution about the housing market to generate new features\n",
    "    df['bedBathRatio'] = df['BedroomCnt']/df['BathroomCnt'] \n",
    "    df['yardSqft'] = df['LotSizeSquareFeet'] - df['FinishedSquareFeet'] #should subtract garage too\n",
    "    df['age'] = 2015 - df['BuiltYear']\n",
    "    df['sqftPerFloor'] = df['FinishedSquareFeet']/df['StoryCnt']\n",
    "    df['sqftPerBed'] = df['FinishedSquareFeet']/df['BedroomCnt']\n",
    "    df['sqftPerBath'] = df['FinishedSquareFeet']/df['BathroomCnt']\n",
    "    df['new'] = (df['age']==0).astype(int)\n",
    "    df['noVacant'] = (df['BGPctVacant']==0).astype(int)\n",
    "    df['richRent'] = (df['BGMedRent']>2000).astype(int)\n",
    "    df['richHome'] = (df['BGMedHomeValue']>1000000).astype(int)\n",
    "    for var in ['FinishedSquareFeet','GarageSquareFeet','LotSizeSquareFeet','sqftPerFloor','sqftPerBed','sqftPerBath']:\n",
    "        df['log'+var] = np.log(df[var])\n",
    "\n",
    "    #dummy for has garage\n",
    "    df['HasGarage'] = (np.isnan(df['GarageSquareFeet'])).astype(int)\n",
    "\n",
    "    # drop some useless vars\n",
    "    df = df.drop(['latitudes', 'longitudes', 'Unnamed: 0', 'censusblockgroup', 'Usecode', 'TransDate'], axis=1)\n",
    "\n",
    "    #fix missing values\n",
    "    df.fillna(-999, inplace=True)\n",
    "\n",
    "    #convert to int for cat_features\n",
    "    df['ViewType'] = df['ViewType'].astype(int)\n",
    "        \n",
    "    y = df['SaleDollarCnt']\n",
    "    x = df.loc[:, 'ZoneCodeCounty':]\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "xTrain = dataPrep(dfTrain)[0]\n",
    "yTrain = dataPrep(dfTrain)[1]\n",
    "yLogTrain = np.log(yTrain)\n",
    "\n",
    "xTest = dataPrep(dfTest)[0]\n",
    "#yTest = dataPrep(dfTest)[1]\n",
    "#yLogTest = np.log(yTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #exploratory analysis\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(8,5))\n",
    "# ax.hist(yTrain, bins=30)\n",
    "# ax.set_ylabel('SaleDollarCnt')\n",
    "# plt.show()\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(8,5))\n",
    "# ax.hist(yLogTrain, bins=30)\n",
    "# ax.set_ylabel('ln(SaleDollarCnt)')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prep for pipeline and define some utility functions\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def polyMaker(data,power):\n",
    "    poly = PolynomialFeatures(power)\n",
    "    poly_train = pd.DataFrame(poly.fit_transform(data))\n",
    "    poly_train = poly_train.add_prefix('poly_').set_index(data.index)\n",
    "    #concatenate the poly dataframe with original but drop the first xTrainEnc.shape[1]+1 cols because this or first ordered polynomials\n",
    "    return pd.concat([data,poly_train.loc[:,'poly_'+str(data.shape[1]+1):]], axis=1)\n",
    "\n",
    "#Important metrics: absPercError = abs(outSample-yTest)/yTest\n",
    "def mape(predicted, actual):\n",
    "    diff = predicted-actual\n",
    "    diffRatio = diff/actual\n",
    "    absPercError = abs(diffRatio)\n",
    "    return 100*absPercError.median()\n",
    "def aape(predicted, actual):\n",
    "    diff = predicted-actual\n",
    "    diffRatio = diff/actual\n",
    "    absPercError = abs(diffRatio)\n",
    "    return 100*absPercError.mean()\n",
    "\n",
    "def logError(predicted, actual):\n",
    "    return ln(predicted/actual)\n",
    "\n",
    "myScore = make_scorer(logError, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build class with transformer function to use within pipeline \n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from IPython.display import clear_output\n",
    "\n",
    "pd.options.mode.chained_assignment = None #the mapping function is fine\n",
    "\n",
    "class myTransformerClass(BaseEstimator, TransformerMixin):\n",
    "    #Class Constructor \n",
    "    def __init__(self, incluCatCols):\n",
    "        self._incluCatCols = incluCatCols\n",
    "        \n",
    "    #Return self nothing else to do here    \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \n",
    "        #generate some features relative to block- and tract-level means\n",
    "        for var in ['StoryCnt','BedroomCnt','FinishedSquareFeet','LotSizeSquareFeet','age']:\n",
    "\n",
    "            globalMean = X[var].mean()\n",
    "            FIPSmean = X.groupby('FIPS')[var].mean() \n",
    "            X['Block'+var] = X['FIPS'].map(FIPSmean)\n",
    "            tractFIPSmean = X.groupby('tractFIPS')[var].mean()\n",
    "            X['Tract'+var] = X['tractFIPS'].map(tractFIPSmean)\n",
    "            X.fillna(globalMean, inplace=True) #for unmatched FIPS fill the ratio with the global mean \n",
    "            #relative features\n",
    "            X['relBlock'+var]= X[var]/X['Block'+var]\n",
    "            X['relTract'+var]= X[var]/X['Tract'+var]\n",
    "            X.fillna(1,inplace=True) \n",
    "\n",
    "        #need to drop categorical columns for preprocessing on numerical vars (polynomials and scaling)\n",
    "        catCols = ['FIPS','tractFIPS','ViewType','ZoneCodeCounty']\n",
    "        xNoCat = X.drop(catCols, axis=1)\n",
    "        \n",
    "        #add polynomial interaction terms\n",
    "        xNoCatPoly = xNoCat #polyMaker(xNoCat,2)\n",
    "            \n",
    "        #scalar\n",
    "        xScaler = StandardScaler().fit(xNoCatPoly) \n",
    "        xNoCatPolyScaled = pd.DataFrame(xScaler.transform(xNoCatPoly))\n",
    "            \n",
    "        #now add back our categorical data to the catboost sample\n",
    "        xNew = pd.concat([X[catCols],pd.DataFrame(xNoCatPolyScaled).set_index(X.index)],axis=1)\n",
    "        \n",
    "        return xNew\n",
    "    \n",
    "def myTransform(X):        \n",
    "    #generate some features relative to block- and tract-level means\n",
    "    for var in ['StoryCnt','BedroomCnt','FinishedSquareFeet','LotSizeSquareFeet','age']:\n",
    "\n",
    "        globalMean = X[var].mean()\n",
    "        FIPSmean = X.groupby('FIPS')[var].mean() \n",
    "        X['Block'+var] = X['FIPS'].map(FIPSmean)\n",
    "        tractFIPSmean = X.groupby('tractFIPS')[var].mean()\n",
    "        X['Tract'+var] = X['tractFIPS'].map(tractFIPSmean)\n",
    "        X.fillna(globalMean, inplace=True) #for unmatched FIPS fill the ratio with the global mean \n",
    "        #relative features\n",
    "        X['relBlock'+var]= X[var]/X['Block'+var]\n",
    "        X['relTract'+var]= X[var]/X['Tract'+var]\n",
    "        X.fillna(1,inplace=True) \n",
    "\n",
    "\n",
    "    #need to drop categorical columns for preprocessing on numerical vars (polynomials and scaling)\n",
    "    catCols = ['FIPS','tractFIPS','ViewType','ZoneCodeCounty']\n",
    "    xNoCat = X.drop(catCols, axis=1)\n",
    "\n",
    "\n",
    "    #add polynomial interaction terms\n",
    "    xNoCatPolyScaled = xNoCat #polyMaker(xNoCat,2)\n",
    "\n",
    "    #scalar\n",
    "#     xScaler = StandardScaler().fit(xNoCatPoly) \n",
    "#     xNoCatPolyScaled = pd.DataFrame(xScaler.transform(xNoCatPoly))\n",
    "\n",
    "\n",
    "    #now add back our categorical data to the catboost sample\n",
    "    xNew = pd.concat([X[catCols],pd.DataFrame(xNoCatPolyScaled).set_index(X.index)],axis=1)\n",
    "\n",
    "    return xNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# use pipeline to run catboost and optimize over hyper parameters\n",
    "import catboost\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(xTrain, yLogTrain, test_size=0.2)\n",
    "\n",
    "# month=7\n",
    "# x_trainTime = myTransform(xTrain[xTrain['TransMonth']<month])\n",
    "# x_testTime = myTransform(xTrain[xTrain['TransMonth']>=month])\n",
    "\n",
    "# y_trainTime = yLogTrain[xTrain['TransMonth']<month]\n",
    "# y_testTime = yLogTrain[xTrain['TransMonth']>=month]\n",
    "\n",
    "# x_train = myTransform(x_train)\n",
    "# x_test = myTransform(x_test)\n",
    "\n",
    "x_trainNew = myTransform(xTrain)\n",
    "x_testNew = myTransform(xTest)\n",
    "\n",
    "# #Bayesian optimization to tune hyper parameters\n",
    "# model = Pipeline([('data',myTransformerClass(True)),('est',CatBoostRegressor(verbose=500, cat_features = [0,1,2,3]))])\n",
    "\n",
    "# # #Bayesian search to tune hyperparameters\n",
    "# # from skopt import BayesSearchCV\n",
    "# # from sklearn.model_selection import KFold\n",
    "# # from skopt import gp_minimize # Bayesian optimization using Gaussia\n",
    "##from skopt.space import Real, Categorical, Integer\n",
    "# # #from skopt.utils import use_named_args # decorator to convert a list of parameters to named arguments\n",
    "# # import pprint\n",
    "# # from time import time\n",
    "\n",
    "# # kFold = KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "# # search_spaces = {'est__iterations': Integer(300, 500),\n",
    "# #                  'est__depth': Integer(1, 9),\n",
    "# #                  'est__learning_rate': Real(0.01, 1.0),\n",
    "# #                  'est__random_strength': Real(1e-9, 10),\n",
    "# #                  'est__bagging_temperature': Real(0.0, 1.0),\n",
    "# #                  'est__border_count': Integer(1, 255),\n",
    "# #                  'est__l2_leaf_reg': Integer(2, 30)}\n",
    "\n",
    "# # bayes_search = BayesSearchCV(model,\n",
    "# #                     search_spaces,\n",
    "# #                     cv=kFold,\n",
    "# #                     n_iter=100,\n",
    "# #                     n_jobs=1,\n",
    "# #                     optimizer_kwargs={'base_estimator': 'GP'})\n",
    "\n",
    "# # bayes_search.fit(x_train, y_train)\n",
    "\n",
    "# # best_params = bayes_search.best_params_\n",
    "# # print(bayes_search.cv_results_)\n",
    "# # print()\n",
    "# # print(best_params)\n",
    "# # print()\n",
    "# # # rename params in dictionary for use in catboost\n",
    "# # for param in ['est__depth','est__iterations','est__learning_rate','est__l2_leaf_reg','est__random_strength','est__bagging_temperature','est__border_count']:\n",
    "# #      best_params[param[5:]] = best_params.pop(param)\n",
    "# # # take best parameters and train the model\n",
    "# # model = Pipeline([('data',myTransformerClass(True)),('est',CatBoostRegressor(verbose=500, cat_features = [0,1,2,3], **best_params))])\n",
    "# # model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_params = {'depth': 7,\n",
    "#     'iterations': 7996,\n",
    "#     'learning_rate': 0.010914273830478815,\n",
    "#     'l2_leaf_reg': 0,\n",
    "#     'random_strength': 20.0,\n",
    "#     'bagging_temperature': 0.0,\n",
    "#     'border_count': 112}\n",
    "# # best_params = {'bagging_temperature': 1.0, \n",
    "# #                'border_count': 116, \n",
    "# #                'depth': 7, \n",
    "# #                'iterations': 7000, \n",
    "# #                'l2_leaf_reg': 2, \n",
    "# #                'learning_rate': 0.05, \n",
    "# #                'random_strength': 20.0}\n",
    "\n",
    "# from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "# # create categorical feature vector for catboost encoding\n",
    "# catFeatures =[]\n",
    "# catCols = ['FIPS','tractFIPS','ViewType','ZoneCodeCounty']\n",
    "# for cat in catCols:    \n",
    "#     catFeatures.append(x_train.columns.get_loc(cat)) #output indices of categorical features\n",
    "\n",
    "# train_pool = Pool(\n",
    "#     data=x_train, \n",
    "#     label=y_train, \n",
    "#     cat_features=catFeatures\n",
    "# )\n",
    "\n",
    "# eval_pool = Pool(\n",
    "#     data=x_test, \n",
    "#     label=y_test, \n",
    "#     cat_features=catFeatures\n",
    "# )\n",
    "\n",
    "# # #model.fit(x_train[y_train<np.percentile(y_train,98)],y_train[y_train<np.percentile(y_train,98)])\n",
    "# model = CatBoostRegressor(verbose=500,**best_params)\n",
    "\n",
    "# model.fit(train_pool, eval_set=eval_pool, early_stopping_rounds=500)\n",
    "\n",
    "# inSample = np.exp(model.predict(x_train))\n",
    "# outSample = np.exp(model.predict(x_test))\n",
    "\n",
    "# #absPercError = mean(abs(outSample-yTest)/yTest)\n",
    "\n",
    "# # The mean squared error\n",
    "# print(\"Mean squared error (in sample): %.2f\"\n",
    "#     % mean_squared_error(np.exp(y_train), inSample))\n",
    "# #Explained variance score: 1 is perfect prediction\n",
    "# print('R-square (in sample): %.2f' % r2_score(np.exp(y_train), inSample))\n",
    "# print(\"Mean squared error: %.2f\"\n",
    "#     % mean_squared_error(np.exp(y_test), outSample))\n",
    "# print('R-square: %.2f' % r2_score(np.exp(y_test), outSample))\n",
    "# print()\n",
    "# print('Median absolute percentage error: %.2f' % mape(outSample, np.exp(y_test)))\n",
    "# print('Average absolute percentage error: %.2f' % aape(outSample, np.exp(y_test)))\n",
    "# print()\n",
    "# print(model.get_best_iteration())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5283754\ttotal: 229ms\tremaining: 30m 33s\n",
      "500:\tlearn: 0.1913794\ttotal: 44.4s\tremaining: 11m 4s\n",
      "1000:\tlearn: 0.1694989\ttotal: 1m 28s\tremaining: 10m 18s\n",
      "1500:\tlearn: 0.1435320\ttotal: 2m 7s\tremaining: 9m 10s\n",
      "2000:\tlearn: 0.1283527\ttotal: 2m 43s\tremaining: 8m 8s\n",
      "2500:\tlearn: 0.1172954\ttotal: 3m 19s\tremaining: 7m 17s\n",
      "3000:\tlearn: 0.1083561\ttotal: 3m 55s\tremaining: 6m 31s\n",
      "3500:\tlearn: 0.1007274\ttotal: 4m 37s\tremaining: 5m 55s\n",
      "4000:\tlearn: 0.0943429\ttotal: 5m 18s\tremaining: 5m 18s\n",
      "4500:\tlearn: 0.0887784\ttotal: 5m 56s\tremaining: 4m 36s\n",
      "5000:\tlearn: 0.0836975\ttotal: 6m 33s\tremaining: 3m 55s\n",
      "5500:\tlearn: 0.0790850\ttotal: 7m 9s\tremaining: 3m 14s\n",
      "6000:\tlearn: 0.0749071\ttotal: 7m 45s\tremaining: 2m 34s\n",
      "6500:\tlearn: 0.0711084\ttotal: 8m 21s\tremaining: 1m 55s\n",
      "7000:\tlearn: 0.0674850\ttotal: 9m\tremaining: 1m 16s\n",
      "7500:\tlearn: 0.0641501\ttotal: 9m 35s\tremaining: 38s\n",
      "7995:\tlearn: 0.0611009\ttotal: 10m 11s\tremaining: 0us\n",
      "0:\tlearn: 0.5287706\ttotal: 79ms\tremaining: 10m 32s\n",
      "500:\tlearn: 0.1920688\ttotal: 37.4s\tremaining: 9m 19s\n",
      "1000:\tlearn: 0.1708542\ttotal: 1m 11s\tremaining: 8m 16s\n",
      "1500:\tlearn: 0.1451041\ttotal: 1m 46s\tremaining: 7m 40s\n",
      "2000:\tlearn: 0.1297085\ttotal: 2m 21s\tremaining: 7m 4s\n",
      "2500:\tlearn: 0.1183523\ttotal: 2m 56s\tremaining: 6m 28s\n",
      "3000:\tlearn: 0.1094998\ttotal: 3m 32s\tremaining: 5m 53s\n",
      "3500:\tlearn: 0.1019499\ttotal: 4m 7s\tremaining: 5m 17s\n",
      "4000:\tlearn: 0.0957018\ttotal: 4m 43s\tremaining: 4m 42s\n",
      "4500:\tlearn: 0.0901798\ttotal: 5m 21s\tremaining: 4m 9s\n",
      "5000:\tlearn: 0.0851707\ttotal: 5m 56s\tremaining: 3m 33s\n",
      "5500:\tlearn: 0.0803903\ttotal: 6m 33s\tremaining: 2m 58s\n",
      "6000:\tlearn: 0.0760258\ttotal: 7m 13s\tremaining: 2m 24s\n",
      "6500:\tlearn: 0.0720897\ttotal: 7m 49s\tremaining: 1m 47s\n",
      "7000:\tlearn: 0.0684726\ttotal: 8m 24s\tremaining: 1m 11s\n",
      "7500:\tlearn: 0.0651455\ttotal: 9m\tremaining: 35.7s\n",
      "7995:\tlearn: 0.0621189\ttotal: 9m 37s\tremaining: 0us\n",
      "0:\tlearn: 0.5277173\ttotal: 79.6ms\tremaining: 10m 36s\n",
      "500:\tlearn: 0.1930682\ttotal: 36.6s\tremaining: 9m 7s\n",
      "1000:\tlearn: 0.1707095\ttotal: 1m 10s\tremaining: 8m 13s\n",
      "1500:\tlearn: 0.1442991\ttotal: 1m 46s\tremaining: 7m 39s\n",
      "2000:\tlearn: 0.1286660\ttotal: 2m 21s\tremaining: 7m 4s\n",
      "2500:\tlearn: 0.1172937\ttotal: 2m 57s\tremaining: 6m 30s\n",
      "3000:\tlearn: 0.1085292\ttotal: 3m 33s\tremaining: 5m 55s\n",
      "3500:\tlearn: 0.1011760\ttotal: 4m 8s\tremaining: 5m 18s\n",
      "4000:\tlearn: 0.0947489\ttotal: 4m 46s\tremaining: 4m 45s\n",
      "4500:\tlearn: 0.0892877\ttotal: 5m 23s\tremaining: 4m 11s\n",
      "5000:\tlearn: 0.0843710\ttotal: 6m\tremaining: 3m 36s\n",
      "5500:\tlearn: 0.0798874\ttotal: 6m 36s\tremaining: 2m 59s\n",
      "6000:\tlearn: 0.0756444\ttotal: 7m 11s\tremaining: 2m 23s\n",
      "6500:\tlearn: 0.0718005\ttotal: 7m 46s\tremaining: 1m 47s\n",
      "7000:\tlearn: 0.0681919\ttotal: 8m 21s\tremaining: 1m 11s\n",
      "7500:\tlearn: 0.0648843\ttotal: 8m 57s\tremaining: 35.4s\n",
      "7995:\tlearn: 0.0618470\ttotal: 9m 34s\tremaining: 0us\n",
      "0:\tlearn: 0.5284663\ttotal: 61.9ms\tremaining: 8m 15s\n",
      "500:\tlearn: 0.1917584\ttotal: 36.3s\tremaining: 9m 2s\n",
      "1000:\tlearn: 0.1710072\ttotal: 1m 9s\tremaining: 8m 7s\n",
      "1500:\tlearn: 0.1453134\ttotal: 1m 48s\tremaining: 7m 48s\n",
      "2000:\tlearn: 0.1299744\ttotal: 2m 24s\tremaining: 7m 13s\n",
      "2500:\tlearn: 0.1187088\ttotal: 3m 4s\tremaining: 6m 45s\n",
      "3000:\tlearn: 0.1096970\ttotal: 3m 47s\tremaining: 6m 18s\n",
      "3500:\tlearn: 0.1022212\ttotal: 4m 31s\tremaining: 5m 48s\n",
      "4000:\tlearn: 0.0954977\ttotal: 5m 12s\tremaining: 5m 12s\n",
      "4500:\tlearn: 0.0898926\ttotal: 5m 54s\tremaining: 4m 34s\n",
      "5000:\tlearn: 0.0847752\ttotal: 6m 36s\tremaining: 3m 57s\n",
      "5500:\tlearn: 0.0800825\ttotal: 7m 18s\tremaining: 3m 18s\n",
      "6000:\tlearn: 0.0758654\ttotal: 7m 59s\tremaining: 2m 39s\n",
      "6500:\tlearn: 0.0719184\ttotal: 8m 41s\tremaining: 1m 59s\n",
      "7000:\tlearn: 0.0683331\ttotal: 9m 20s\tremaining: 1m 19s\n",
      "7500:\tlearn: 0.0650268\ttotal: 9m 58s\tremaining: 39.5s\n",
      "7995:\tlearn: 0.0620137\ttotal: 10m 39s\tremaining: 0us\n",
      "0:\tlearn: 0.5283570\ttotal: 100ms\tremaining: 13m 20s\n",
      "500:\tlearn: 0.1936057\ttotal: 44s\tremaining: 10m 58s\n",
      "1000:\tlearn: 0.1713372\ttotal: 1m 25s\tremaining: 9m 58s\n",
      "1500:\tlearn: 0.1450481\ttotal: 2m 8s\tremaining: 9m 17s\n",
      "2000:\tlearn: 0.1294169\ttotal: 2m 55s\tremaining: 8m 44s\n",
      "2500:\tlearn: 0.1184626\ttotal: 3m 38s\tremaining: 8m 1s\n",
      "3000:\tlearn: 0.1094127\ttotal: 4m 22s\tremaining: 7m 16s\n",
      "3500:\tlearn: 0.1020042\ttotal: 4m 58s\tremaining: 6m 23s\n",
      "4000:\tlearn: 0.0954152\ttotal: 5m 41s\tremaining: 5m 41s\n",
      "4500:\tlearn: 0.0895954\ttotal: 6m 37s\tremaining: 5m 8s\n",
      "5000:\tlearn: 0.0845148\ttotal: 7m 23s\tremaining: 4m 25s\n",
      "5500:\tlearn: 0.0799497\ttotal: 8m 10s\tremaining: 3m 42s\n",
      "6000:\tlearn: 0.0757286\ttotal: 8m 54s\tremaining: 2m 57s\n",
      "6500:\tlearn: 0.0718007\ttotal: 9m 40s\tremaining: 2m 13s\n",
      "7000:\tlearn: 0.0682077\ttotal: 10m 24s\tremaining: 1m 28s\n",
      "7500:\tlearn: 0.0648635\ttotal: 11m 5s\tremaining: 43.9s\n",
      "7995:\tlearn: 0.0616987\ttotal: 11m 52s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "best_params = {'depth': 7,\n",
    "    'iterations': 7996,\n",
    "    'learning_rate': 0.010914273830478815,\n",
    "    'l2_leaf_reg': 0,\n",
    "    'random_strength': 20.0,\n",
    "    'bagging_temperature': 0.0,\n",
    "    'border_count': 112}\n",
    "\n",
    "# numModels = 3\n",
    "# predsTest = [0.0]*numModels\n",
    "# predsTrain = [0.0]*numModels\n",
    "# sumTrain = [0.0]\n",
    "# sumTest = [0.0]\n",
    "# seed = [random.randint(0,100000),random.randint(0,100000),random.randint(0,100000)]\n",
    "# for i in range(numModels):\n",
    "#     model =CatBoostRegressor(verbose=500, cat_features = [0,1,2,3], **best_params, random_seed = seed[i])\n",
    "#     model.fit(x_train, y_train)\n",
    "#     predsTrain[i] += model.predict(x_train)\n",
    "#     predsTest[i] += model.predict(x_test)\n",
    "#     sumTrain +=predsTrain[i]\n",
    "#     sumTest +=predsTest[i]\n",
    "\n",
    "# avgTrain = sumTrain/numModels\n",
    "# avgTest = sumTest/numModels\n",
    "\n",
    "numModels = 5\n",
    "predsTest = [0.0]*numModels\n",
    "predsTrain = [0.0]*numModels\n",
    "sumTrain = [0.0]\n",
    "sumTest = [0.0]\n",
    "seed = [random.randint(0,100000),random.randint(0,100000),random.randint(0,100000),random.randint(0,100000),random.randint(0,100000)]\n",
    "for i in range(numModels):\n",
    "    model =CatBoostRegressor(verbose=500, cat_features = [0,1,2,3], **best_params, random_seed = seed[i])\n",
    "    model.fit(x_trainNew, yLogTrain)\n",
    "    predsTrain[i] += model.predict(x_trainNew)\n",
    "    predsTest[i] += model.predict(x_testNew)\n",
    "    sumTrain +=predsTrain[i]\n",
    "    sumTest +=predsTest[i]\n",
    "\n",
    "avgTrain = sumTrain/numModels\n",
    "avgTest = sumTest/numModels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model =CatBoostRegressor(verbose=500, cat_features = [0,1,2,3], **best_params)\n",
    "# model.fit(x_trainTime, y_trainTime)\n",
    "\n",
    "# inSample = np.exp(model.predict(x_trainTime))\n",
    "# outSample = np.exp(model.predict(x_testTime))\n",
    "\n",
    "# #absPercError = mean(abs(outSample-yTest)/yTest)\n",
    "\n",
    "# # The mean squared error\n",
    "# print(\"Mean squared error (in sample): %.2f\"\n",
    "#     % mean_squared_error(np.exp(y_trainTime), inSample))\n",
    "# #Explained variance score: 1 is perfect prediction\n",
    "# print('R-square (in sample): %.2f' % r2_score(np.exp(y_trainTime), inSample))\n",
    "# print(\"Mean squared error: %.2f\"\n",
    "#     % mean_squared_error(np.exp(y_testTime), outSample))\n",
    "# print('R-square: %.2f' % r2_score(np.exp(y_testTime), outSample))\n",
    "# print()\n",
    "# print('Median absolute percentage error: %.2f' % mape(outSample, np.exp(y_testTime)))\n",
    "# print('Average absolute percentage error: %.2f' % aape(outSample, np.exp(y_testTime)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "x_trainNew['predicted'] = avgTrain\n",
    "x_testNew['predicted'] = avgTest\n",
    "\n",
    "x_trainNew['const'] = 1\n",
    "x_trainNew['day'] = x_trainNew['TransDayOfYear']\n",
    "x_trainNew['daysq'] = np.power(x_trainNew['TransDayOfYear'],2)\n",
    "x_trainNew['daycu'] = np.power(x_trainNew['TransDayOfYear'],3)\n",
    "x_trainNew['week'] = x_trainNew['TransWeek']\n",
    "x_trainNew['weeksq'] = np.power(x_trainNew['TransWeek'],2)\n",
    "x_trainNew['weekcu'] = np.power(x_trainNew['TransWeek'],3)\n",
    "x_trainNew = x_trainNew.loc[:,'predicted':]\n",
    "x_trainNew.fillna(x_trainNew.mean(), inplace=True)\n",
    "\n",
    "x_testNew['const'] = 1\n",
    "x_testNew['day'] = x_testNew['TransDayOfYear']\n",
    "x_testNew['daysq'] = np.power(x_testNew['TransDayOfYear'],2)\n",
    "x_testNew['daycu'] = np.power(x_testNew['TransDayOfYear'],3)\n",
    "x_testNew['week'] = x_testNew['TransWeek']\n",
    "x_testNew['weeksq'] = np.power(x_testNew['TransWeek'],2)\n",
    "x_testNew['weekcu'] = np.power(x_testNew['TransWeek'],3)\n",
    "x_testNew = x_testNew.loc[:,'predicted':]\n",
    "x_testNew.fillna(x_testNew.mean(), inplace=True)    \n",
    "\n",
    "lasso =Lasso(0.005, max_iter=25000)\n",
    "lasso.fit(x_trainNew, yLogTrain)\n",
    "\n",
    "predTrain = lasso.predict(x_trainNew)\n",
    "predTest = lasso.predict(x_testNew)\n",
    "\n",
    "# x_trainTime['predicted'] = model.predict(x_trainTime)\n",
    "# x_testTime['predicted'] = model.predict(x_testTime)\n",
    "\n",
    "\n",
    "# x_trainTime['const'] = 1\n",
    "# x_trainTime['day'] = x_trainTime['TransDayOfYear']\n",
    "# x_trainTime['daysq'] = np.power(x_trainTime['TransDayOfYear'],2)\n",
    "# x_trainTime['daycu'] = np.power(x_trainTime['TransDayOfYear'],3)\n",
    "# x_trainTime['week'] = x_trainTime['TransWeek']\n",
    "# x_trainTime['weeksq'] = np.power(x_trainTime['TransWeek'],2)\n",
    "# x_trainTime['weekcu'] = np.power(x_trainTime['TransWeek'],3)\n",
    "# x_trainTime = x_trainTime.loc[:,'predicted':]\n",
    "# x_trainTime.fillna(x_trainTime.mean(), inplace=True)\n",
    "\n",
    "# x_testTime['const'] = 1\n",
    "# x_testTime['day'] = x_testTime['TransDayOfYear']\n",
    "# x_testTime['daysq'] = np.power(x_testTime['TransDayOfYear'],2)\n",
    "# x_testTime['daycu'] = np.power(x_testTime['TransDayOfYear'],3)\n",
    "# x_testTime['week'] = x_testTime['TransWeek']\n",
    "# x_testTime['weeksq'] = np.power(x_testTime['TransWeek'],2)\n",
    "# x_testTime['weekcu'] = np.power(x_testTime['TransWeek'],3)\n",
    "# x_testTime = x_testTime.loc[:,'predicted':]\n",
    "# x_testTime.fillna(x_testTime.mean(), inplace=True)    \n",
    "\n",
    "# lasso =Lasso(0.001, max_iter=25000)\n",
    "# lasso.fit(x_trainTime, y_trainTime)\n",
    "\n",
    "# predTrain = lasso.predict(x_trainTime)\n",
    "# predTest = lasso.predict(x_testTime)\n",
    "\n",
    "# print('Median absolute percentage error: %.2f' % mape(np.exp(predTest), np.exp(y_testTime)))\n",
    "# print('Average absolute percentage error: %.2f' % aape(np.exp(predTest), np.exp(y_testTime)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame([])\n",
    "results['PropertyID'] = dfTest['PropertyID']\n",
    "results['SaleDollarCnt'] = np.exp(predTest)\n",
    "pd.DataFrame(results).to_csv('zillowResultsWagner.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4402"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fi = model.get_feature_importance(train_pool, type=\"Interaction\")\n",
    "\n",
    "# fi_new = []\n",
    "# for k,item in enumerate(fi):  \n",
    "#     first = x_train.dtypes.index[fi[k][0]]\n",
    "#     second = x_train.dtypes.index[fi[k][1]]\n",
    "#     if first != second:\n",
    "#         fi_new.append([first + \"_\" + second, fi[k][2]])\n",
    "\n",
    "# feature_score = pd.DataFrame(fi_new,columns=['Feature-Pair','Score'])\n",
    "\n",
    "# feature_scoreTop = feature_score[:-1650]\n",
    "# feature_scoreTop = feature_scoreTop.sort_values(by='Score', ascending=False, inplace=False, kind='quicksort', na_position='last')\n",
    "# plt.rcParams[\"figure.figsize\"] = (16,7)\n",
    "# ax = feature_scoreTop.plot('Feature-Pair', 'Score', kind='bar', color='c')\n",
    "# ax.set_title(\"Pairwise Feature Importance\", fontsize = 14)\n",
    "# ax.set_xlabel(\"features Pair\")\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# x_trainNew = myTransform(x_train)\n",
    "# x_testNew = myTransform(x_test)\n",
    "\n",
    "# model= CatBoostRegressor(verbose=500, cat_features = [0,1,2,3])\n",
    "# train_pool = Pool(\n",
    "#     data=x_trainNew, \n",
    "#     label=y_train, \n",
    "#     cat_features=[0,1,2,3]\n",
    "# )\n",
    "\n",
    "# validation_pool = Pool(\n",
    "#     data=x_testNew, \n",
    "#     label=y_test, \n",
    "#     cat_features=[0,1,2,3]\n",
    "# )\n",
    "# model.fit(train_pool)\n",
    "\n",
    "#shap_values = explainer.shap_values(x_train)\n",
    "shap_values = model.get_feature_importance(\n",
    "    train_pool,\n",
    "    'ShapValues'\n",
    ")\n",
    "expected_value = shap_values[0,-1]\n",
    "shap_values = shap_values[:,:-1]\n",
    "\n",
    "shap.summary_plot(shap_values, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#take our best parameters and and fit them to the full training set\n",
    "\n",
    "\n",
    "# numModels = 5\n",
    "# preds = [0.0]*numModels\n",
    "# sum = [0.0]\n",
    "# for i in range(numModels):\n",
    "#     ctboost = Pipeline([('data',myTransformerClass(True)),('est',CatBoostRegressor(randomverbose=500, cat_features = [0,1,2,3], **best_params))])\n",
    "#     ctboost.fit(xTrain, yLogTrain)\n",
    "#     preds[i] += model.predict(xTest)\n",
    "#     sum +=preds[i]\n",
    "#     #i+=1\n",
    "# avg = sum/numModels\n",
    "\n",
    "# ctboost = Pipeline([('data',myTransformerClass(True)),('est',CatBoostRegressor(verbose=500, cat_features = [0,1,2,3], **best_params))])\n",
    "# ctboost.fit(xTrain, yLogTrain)\n",
    "\n",
    "# #creat a vector of predicted sales\n",
    "# yTrainLnPred = ctboost.predict(xTrain)\n",
    "# yTrainPred = np.exp(yTrainLnPred)\n",
    "\n",
    "# yTestLnPred = ctboost.predict(xTest)\n",
    "# yTestPred = np.exp(yTestLnPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thus far the analysis has ignored the time trend in the housing market\n",
    "# # to mitigate this problem, the predictions from catboost are used as regressors in a linear regression model with a time trend\n",
    "# xTrain['ln_predicted'] = yTrainLnPred\n",
    "# xTrain['predicted'] = yTrainPred\n",
    "\n",
    "# xTest['ln_predicted'] = yTestLnPred\n",
    "# xTest['predicted'] = yTestPred\n",
    "\n",
    "# #linear regression does not handle categorical data on it's own, so we need to do some target encoding\n",
    "# train = pd.DataFrame(yLogTrain).merge(x_train, left_index=True, right_index=True)\n",
    "# #target encoding\n",
    "# for cols in ['FIPS','tractFIPS','ViewType','ZoneCodeCounty']:\n",
    "#     global_mean = train['SaleDollarCnt'].mean() #calc global mean\n",
    "#     groupMeans = train.groupby(cols)['SaleDollarCnt'].mean() #mean by group\n",
    "#     xTrain[cols] = xTrain[cols].map(groupMeans) # map the groupMeans onto column in train set (replacing this col)\n",
    "#     xTrain[cols].fillna(global_mean, inplace=True) #if empty (no group mean, only one obs) replace with global_mean\n",
    "#     xTest[cols] = xTest[cols].map(groupMeans) # map the groupMeans onto column in test set (replacing this col)\n",
    "#     xTest[cols].fillna(global_mean, inplace=True) \n",
    "\n",
    "# from sklearn.linear_model import Lasso\n",
    "\n",
    "# lasso = Pipeline([('data',myTransformerClass(False)),('est',Lasso(0.01, max_iter=50000))])\n",
    "# lasso.fit(xTrain, yTrain)\n",
    "\n",
    "# predSalesDollarCnt = np.exp(lass.predict(xTest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numModels = 5\n",
    "# preds = [0.0]*numModels\n",
    "# sum = [0.0]\n",
    "# for i in range(numModels):\n",
    "#     model = CatBoostRegressor(**optParams, random_seed = i, verbose=False)\n",
    "#     model.fit(xTrain, yTrain, cat_features=cat_features)\n",
    "#     preds[i] += model.predict(xTest)\n",
    "#     sum +=preds[i]\n",
    "#     #i+=1\n",
    "# avg = sum/numModels\n",
    "\n",
    "# print(\"Mean squared error: %.2f\"\n",
    "#       % mean_squared_error(yTest, avg))\n",
    "# print('R-square: %.2f' % r2_score(yTest, avg))\n",
    "# print()\n",
    "# print('Median absolute percentage error: %.2f' % mape(avg, yTest))\n",
    "# print('Average absolute percentage error: %.2f' % aape(avg, yTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
